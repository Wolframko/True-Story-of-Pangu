# Трагедия Паньгу: Сердца и Тьма в Истории Разработки Больших Моделей Huawei Noah's Ark Pangu

Привет всем,

Я сотрудник команды большой модели Pangu, лаборатории Huawei Noah's Ark.

Прежде всего, чтобы подтвердить свою личность, приведу несколько деталей:

1. Нынешний директор Noah, бывший руководитель отдела алгоритмических приложений, позже переименованный в руководителя лаборатории малых моделей Ван Юньхэ. Бывший директор Noah: Яо Цзюнь (все называли его Учителем Яо). Несколько руководителей лабораторий: Тан Руймин (Брат Мин, Капитан Мин, уже уволился), Шан Лифэн, Чжан Вэй (Брат Вэй), Хао Цзянье (Учитель Хао), Лю Улун (называли Исследователем Улуном) и другие. Многие другие ключевые члены и эксперты также постепенно ушли.
2. Мы принадлежим к организации "Четыре поля" (四野). Под "Четырьмя полями" находится множество корпусов, и базовые языковые большие модели — это Четвертый корпус. Малые модели Ван Юньхэ — это Шестнадцатый корпус. Мы участвовали в сборах в Сучжоу, были разные временные этапы. На штурмовом совещании в Сучжоу выдавали задачи, которые нужно было выполнить к определенному сроку. На сборах в Сучжоу персонал со всех мест собирался в исследовательском институте Сучжоу, обычно жили в гостиницах, например, в гостинице в Лучжи, вдали от семей и детей.
3. Во время сборов в Сучжоу по субботам по умолчанию работали, было очень тяжело, но по субботам был полдник, а однажды даже были лангусты. Рабочие места в исследовательском институте Сучжоу переезжали один раз, из одного здания в другое. Здания исследовательского института Сучжоу все выполнены в европейском стиле, у входа большой склон, а внутри очень красивые виды. На сборы в Сучжоу обычно нужно было ехать минимум на неделю, а то и дольше, многие не могли вернуться домой даже месяц-два.
4. Когда-то говорили, что Noah — это исследовательская организация, но после прихода, из-за работы над большими моделями в "Четырех полях", сотрудники проекта полностью превратились в "ориентированных на доставку", с кучей совещаний, рецензий, отчетов. Часто для проведения экспериментов нужно было подавать заявки. Команде приходилось взаимодействовать с множеством бизнес-линий, таких как терминальный Xiao Yi, Huawei Cloud, ICT, и давление по доставке было немалым.
5. Ранняя внутренняя кодовое название разработанной Noah модели Pangu называлось "Паньгу Чжицзы", изначально это была только внутренняя веб-версия, доступная по заявке, а затем, под давлением, она была интегрирована в Welink и открыта для публичного тестирования.

В эти дни поднялся большой шум вокруг обвинений в плагиате большой модели Pangu у Qwen. Будучи членом команды Pangu, я в последние дни не могу уснуть. Бренд Pangu так сильно пострадал, с одной стороны, я эгоистично беспокоюсь за свою карьерную траекторию, а также чувствую, что моя прошлая усердная работа была напрасной. С другой стороны, поскольку кто-то начал раскрывать эти вещи, я испытываю большое удовлетворение. Сколько ночей мы скрежетали зубами от бессилия, видя, как некоторые люди внутри компании раз за разом наживаются на фальсификациях. Это давление и унижение постепенно ослабляли мои чувства к Huawei, заставляя меня проводить здесь дни в полусне, растерянности, часто сомневаясь в смысле своей жизни и своей самооценке.

Признаю, я трус. Будучи скромным работником, я не только не осмеливаюсь противостоять таким влиятельным людям внутри компании, как Ван Юньхэ, но и не осмеливаюсь противостоять такому гиганту, как Huawei. Я очень боюсь потерять свою работу, ведь у меня тоже есть семья и дети, поэтому я искренне восхищаюсь разоблачителем. Однако, видя, как внутри компании все еще пытаются отмыться и скрыть факты, обманывая общественность, я просто не могу этого терпеть. Я надеюсь проявить храбрость один раз, последовать своему внутреннему голосу. Даже если я потеряю восемьсот, я надеюсь нанести ущерб в тысячу. Я решил предать огласке то, что я здесь видел и слышал (часть из устных рассказов коллег), о "легендарной истории" большой модели Pangu:

Huawei действительно в основном тренирует большие модели на картах Ascend (в лаборатории малых моделей много карт Nvidia, они раньше тоже использовали их для обучения, потом перешли на Ascend). Когда-то меня поразила решимость Huawei "создать второй выбор для мира", и я сам когда-то испытывал глубокие чувства к Huawei. Мы шаг за шагом продирались сквозь тернии с Ascend, от бесчисленных ошибок до способности обучать модели, вложив огромные усилия и заплатив высокую цену.

Изначально наши вычислительные мощности были крайне ограничены, мы тренировали модели на 910A. Тогда поддерживался только fp16, стабильность обучения была намного хуже, чем у bf16. Pangu moe (mixture of experts) началась очень рано, в 23 году в основном тренировали 38B moe модель и последующую 71B dense модель. 71B dense модель была расширена до первого поколения 135B dense модели, после чего основная модель также постепенно тренировалась на 910B.

У моделей 71B и 135B был огромный недостаток – токенизатор. Используемый в то время токенизатор имел крайне низкую эффективность кодирования: каждый отдельный символ, цифра, пробел и даже китайский иероглиф занимал один токен. Понятно, что это приводило к огромным потерям вычислительной мощности и ухудшало производительность модели. В это время у лаборатории малых моделей как раз был собственный обученный словарь. Учитель Яо тогда заподозрил, что токенизатор модели плох (хотя, как показало время, его подозрения были несомненно верными), и поэтому решил заменить токенизатор для 71B и 135B, так как лаборатория малых моделей уже пробовала это. Команда соединила два токенизатора и приступила к замене. Замена для модели 71B не удалась, а для 135B, благодаря более точной стратегии инициализации эмбеддингов, токенизатор наконец-то был успешно заменен после дообучения как минимум на 1Т данных, но, как можно догадаться, эффект не улучшился.

Одновременно с этим, Alibaba и Zhipu, а также другие китайские компании, обучали модели на GPU и уже освоили правильные методы, и разрыв между Pangu и конкурентами постоянно увеличивался. Внутренняя 230B модель, обученная dense моделью с нуля, также провалилась по разным причинам, что привело к практически безвыходной ситуации для проекта. Столкнувшись с давлением нескольких этапов и сильным внутренним сомнением в Pangu, моральный дух команды был крайне низким. Команда, имея крайне ограниченные вычислительные мощности, приложила много усилий и боролась. Например, команда случайно обнаружила, что тогдашняя 38B moe модель не имела ожидаемого эффекта moe. Поэтому параметры moe были удалены, и модель была возвращена к 13B dense модели. Поскольку 38B moe модель была основана на очень ранней pangu alpha 13B, архитектура была относительно устаревшей, команда провела ряд операций, таких как переключение абсолютного позиционного кодирования на rope, удаление смещения, переключение на rmsnorm. В то же время, учитывая некоторые неудачи с токенизатором и опыт замены словарей, словарь этой модели также был заменен на словарь, используемый моделью 7B лаборатории малых моделей Ван Юньхэ. Позднее эта 13B модель была расширена и дообучена, превратившись во второе поколение 38B dense модели (в течение нескольких месяцев эта модель была основной моделью Pangu среднего уровня), когда-то имевшей определенную конкурентоспособность. Однако, из-за устаревшей архитектуры большей 135B модели и огромных повреждений модели при замене словаря (последующий анализ показал, что соединенный словарь, замененный тогда, имел более серьезные ошибки), после дообучения она все еще сильно отставала от ведущих отечественных моделей, таких как Qwen. В это время внутренние сомнения и давление со стороны руководства также возрастали. Состояние команды почти зашло в тупик.

В такой ситуации Ван Юньхэ и его лаборатория малых моделей вышли на сцену. Они утверждали, что их модель была унаследована и модифицирована из старых параметров 135B, и что, обучив всего лишь несколько сотен миллиардов данных, они улучшили все показатели в среднем на десять процентов. На самом деле, это был их первый шедевр по "обертке" и применению к большой модели. Руководство Huawei, будучи неспециалистами, не имело никакого представления об этой абсурдной ситуации; они просто думали, что это, должно быть, какое-то алгоритмическое новшество. После внутреннего анализа выяснилось, что они фактически использовали Qwen 1.5 110B для дообучения, добавляя слои, расширяя размерность FFN и внедряя некоторые механизмы из статьи Pangu pi, чтобы набрать около 135B параметров. На самом деле, старая 135B модель имела 107 слоев, а эта модель имела только 82 слоя, и все их конфигурации были разными. Многие распределения параметров новой модели 135B, происхождение которой неизвестно, после обучения были почти идентичны Qwen 110B. Даже имя класса в коде модели тогда было Qwen, им даже было лень его менять. Впоследствии эта модель стала так называемой 135B V2. И эта модель тогда предоставлялась многим нижестоящим пользователям, даже внешним клиентам.

Это событие стало огромным потрясением для нас, добросовестных и честных коллег. Многие внутри компании знали об этом, даже в отделах терминалов и Huawei Cloud. Мы в шутку называли модель Pangu "Qangu" (от Qwen и Pangu). Тогда члены команды хотели сообщить об этом в BCG, ведь это уже было серьезное деловое мошенничество. Однако, по слухам, позже руководство пресекло это, потому что руководители более высокого уровня (например, Учитель Яо, и, возможно, Президент Сюн и Старейшина Чжа) на самом деле тоже знали об этом, но не вмешивались, потому что получение хороших результатов путем "упаковки" было выгодно и для них. Это событие заставило нескольких самых сильных коллег в команде впасть в уныние, и разговоры об увольнении постепенно стали обыденным делом.

В этот момент, казалось, для Pangu наступил переломный момент. Поскольку все вышеупомянутые модели Pangu были в основном дообучены и модифицированы, в то время Noah вообще не владел технологией обучения с нуля, тем более на NPU Ascend. Благодаря настойчивым усилиям ключевых членов команды Pangu приступил к обучению моделей третьего поколения, приложив огромные усилия, и постепенно сравнялся с отраслью в области архитектуры данных и алгоритмов обучения, и люди из лаборатории малых моделей не имели к этому ни малейшего отношения.

Сначала члены команды не верили в успех, начав обучение с модели 13B, но затем обнаружили, что результаты довольно хорошие, поэтому эта модель впоследствии была расширена еще раз, превратившись в третье поколение 38B, под кодовым названием 38B V3. Наверняка многие братья из продуктовых линеек хорошо знакомы с этой моделью. В то время токенизатор этой модели был расширен на основе словаря Llama (что также является распространенной практикой в отрасли). В то же время лаборатория Ван Юньхэ разработала еще один словарь (тот, который впоследствии использовался в серии Pangu). Тогда два словаря были вынуждены участвовать в соревновании, и в конечном итоге не было выявлено явных преимуществ или недостатков. Поэтому руководство немедленно решило унифицировать словари, используя их словарь Ван Юньхэ. Таким образом, в последующем обучении с нуля 135B V3 (то есть внешний Pangu Ultra) использовался этот токенизатор. Это также объясняет недоумение многих братьев, использующих нашу модель, почему в то время две модели разных уровней одного и того же поколения V3 использовали разные токенизаторы.

Мы всем сердцем считаем, что 135B V3 — это наша гордость четвертого фронта того времени. Это первая по-настоящему самостоятельно разработанная, правильно обученная с нуля модель уровня ста миллиардов параметров от Huawei, и ее производительность сравнима с конкурентами того же периода 24 года. Пишу эти строки, и у меня на глазах слезы, это было так нелегко. Тогда, чтобы обеспечить стабильное обучение, команда провела множество сравнительных экспериментов и неоднократно своевременно откатывалась и перезапускалась при появлении аномалий в градиентах модели. Эта модель действительно достигла того, что было сказано в последующем техническом отчете: ни одного всплеска потерь за весь процесс обучения. Мы преодолели бесчисленные трудности, мы это сделали, и мы готовы поклясться своей жизнью и честью в достоверности обучения этой модели. Сколько ночей мы не спали ради ее обучения. Когда нас ни за что ругали внутри Huawei, как мы были возмущены, сколько обид мы вынесли, мы выстояли.

Мы, эти люди, действительно сжигали свою молодость, чтобы отточить отечественную вычислительную базу... Живя в чужой стране, мы отказались от семьи, от отпусков, от здоровья, от развлечений, проливали кровь и пот, и тяготы и лишения, которые мы пережили, невозможно описать в нескольких строках. На различных мобилизационных собраниях лозунги "Pangu победит!", "Huawei победит!", которые тогда звучали, искренне трогали наши сердца.

Однако все наши плоды труда часто легко доставались лаборатории малых моделей. Данные, забирали напрямую. Код, забирали напрямую, еще и требовали от нас адаптации, чтобы он запускался одним нажатием кнопки. Мы тогда в шутку называли лабораторию малых моделей "лабораторией кликов мышкой". Мы вкладывали труд, а они пожинают славу. Как говорится, ты несешь ношу, потому что кто-то наслаждается жизнью вместо тебя. В такой боевой обстановке все больше и больше товарищей не могли больше выдержать и выбирали уход. Видя, как один за другим увольняются такие талантливые коллеги, я одновременно восхищаюсь и грущу. В такой боевой обстановке мы были больше похожи на боевых товарищей, чем на коллег. У них было бесчисленное множество вещей, которым я мог бы у них поучиться, они были настоящими учителями. Видя, как они уходят в такие выдающиеся команды, как ByteDance Seed, Deepseek, Moonshot AI, Tencent и Kuaishou, я искренне рад за них и желаю им удачи, освободившись от этого тяжелого, но грязного места. Я до сих пор хорошо помню слова одного ушедшего коллеги, который сказал: "Приход сюда — это позор в моей технической карьере, каждый день, проведенный здесь, — это пустая трата жизни". Хотя слова были неприятными, они оставили меня безмолвным. Я беспокоился о недостатке своих технических знаний и о том, что не смогу приспособиться к высококонкурентной среде интернет-компаний, что неоднократно удерживало меня от ухода, хотя я очень хотел.

Помимо плотной модели, Pangu впоследствии также приступил к исследованию Moe. Сначала обучалась модель Moe на 224B. Параллельно с этим лаборатория малых моделей начала вторую крупную операцию по "обертке" (второстепенные интерлюдии могли включать и другие модели, например, математическую модель), а именно широко распространенную Pangu Pro Moe 72B. Внутри компании утверждалось, что эта модель была расширена из 7B модели лаборатории малых моделей (даже если это так, это не соответствует техническому отчету, не говоря уже о "обертке" Qwen 2.5 14B для дообучения). Я помню, как они обучили ее всего за несколько дней, и внутренние оценки сразу же сравнялись с тогдашней 38B V3. Многие братья из лаборатории AI-систем, которым нужно было адаптировать модель, знали об их операции по "обертке", но по разным причинам не могли добиться справедливости. На самом деле, что касается этой модели, которая обучалась очень долго, я был удивлен, что Honestagi смог проанализировать сходство такого масштаба, потому что вычислительной мощности, потраченной на дообучение для "смывания" параметров, было достаточно, чтобы обучить с нуля модель того же уровня. Я слышал от коллег, что они использовали много методов, чтобы смыть "водяной знак" Qwen, даже преднамеренно обучали на грязных данных. Это также создало беспрецедентный особый прецедент для академических исследований генеалогии моделей. В будущем, когда будут предложены новые методы генеалогии, их можно будет использовать.

В конце 24-го и начале 25-го годов, после выхода Deepseek v3 и r1, из-за их поразительного технического уровня, команда столкнулась с огромным потрясением и еще большим сомнением. Поэтому, чтобы не отставать от тенденций, Pangu, имитируя размер модели Deepseek, начал обучение 718B moe. В этот момент лаборатория малых моделей снова вступила в игру. Они решили использовать Deepseek v3 в качестве основы для дообучения. Они проводили обучение, "замораживая" загруженные параметры Deepseek. Даже каталог для загрузки контрольных точек в задаче был deepseekv3, они даже не потрудились его изменить, насколько это было нагло? В отличие от этого, некоторые коллеги с настоящей технической верой обучали другую 718B moe модель с нуля. Но при этом возникали различные проблемы. Но, очевидно, как эта модель могла быть лучше той, что была напрямую "упакована"? Если бы не упорство руководителя команды, ее бы давно остановили.

Тяжесть процедурного управления в Huawei серьезно замедляла темпы разработки больших моделей, например, управление версиями, происхождение моделей, различные процессы, различные возможности отслеживания. Ирония заключается в том, что модели лаборатории малых моделей, казалось, никогда не подчинялись этим процедурам: хотели "обернуть" – "обертывали", хотели дообучить – дообучали, вычислительные мощности бесконечно забирались. Этот сильный, почти магический контраст демонстрирует текущее состояние процедурного управления: "губернатору разрешено поджигать, а простым людям запрещено зажигать лампу". Как это смешно? Как это печально? Как это отвратительно? Как это позорно!

После того, как произошел инцидент с HonestAGI, внутри компании всех заставили постоянно обсуждать и анализировать, как проводить пиар и "отвечать". Действительно, первоначальный анализ, возможно, был недостаточно убедительным, что дало Ван Юньхэ и лаборатории малых моделей возможность изворачиваться и искажать факты. В связи с этим в последние два дня меня тошнит, и я постоянно сомневаюсь в смысле своей жизни и в том, что небо несправедливо. Я больше не буду участвовать, я увольняюсь, и одновременно я подаю заявку на исключение моего имени из списка авторов некоторых технических отчетов Pangu. Мое имя на этих технических отчетах — это пятно, которое я не смогу стереть всю свою жизнь. Тогда я не думал, что они осмелятся открыть исходный код. Я не думал, что они осмелятся так глупо морочить голову миру, так широко распространяя информацию. Тогда я, возможно, надеялся на удачу и не отказался от соавторства. Я верю, что многие мои товарищи, которые добросовестно работали, были просто вынуждены вступить на этот путь или не знали об этом. Но это уже не изменить, и я надеюсь, что оставшуюся жизнь смогу посвятить добросовестной работе над действительно значимыми вещами, искупив свою тогдашнюю слабость и нерешительность.

Пишу это глубокой ночью, и слезы текут по моему лицу, я рыдаю навзрыд. Помню, когда некоторые выдающиеся коллеги увольнялись, я с горькой усмешкой спрашивал их, не хотят ли они написать длинный обычный пост с жалобой, чтобы раскрыть ситуацию. Они отвечали: "Нет, пустая трата времени, и я боюсь, что если я раскрою это, вам станет еще хуже". Тогда мне стало очень грустно, потому что товарищи, с которыми я когда-то боролся за идеал, полностью разочаровались в Huawei. Тогда все шутили, что мы используем винтовки и ружья, как коммунистическая партия в те годы, а наша организация имеет манеры, сравнимые с Гоминьданом тех лет.

Когда-то я гордился тем, что мы с винтовками и ружьями побеждали западные пушки.

Теперь я устал, я хочу сдаться.

На самом деле, до сих пор я искренне надеюсь, что Huawei серьезно извлечет уроки, сможет хорошо сделать Pangu, сделать Pangu мирового класса, а Ascend — на уровне Nvidia. Внутренняя вытеснение лучшего худшим привело к тому, что Noah и даже Huawei в короткие сроки резко потеряли большое количество выдающихся талантов в области больших моделей. Я верю, что они сейчас сияют в различных командах, таких как Deepseek, реализуя свои амбиции и таланты, внося свой вклад в ожесточенную конкуренцию между Китаем и США в области ИИ. Я часто сетую: в Huawei нет недостатка в талантах, но она просто не знает, как их удержать. Если бы этим людям предоставили подходящую среду, подходящие ресурсы, меньше оков, меньше политической борьбы, разве Pangu не смог бы стать великим?

И наконец: клянусь своей жизнью, личностью и честью, что все, что я написал выше, является правдой (по крайней мере, в пределах моего ограниченного понимания). У меня нет такого высокого технического уровня и возможностей для проведения подробного и тщательного анализа, и я не осмеливаюсь напрямую приводить внутренние записи в качестве доказательств, опасаясь быть пойманным из-за информационной безопасности. Но я верю, что многие мои бывшие товарищи подтвердят мои слова. Братья внутри Huawei, включая братьев из продуктовых линеек, которым мы когда-то служили, я верю, что бесчисленные детали этой статьи совпадут с вашими впечатлениями, подтверждая мои слова. Возможно, вы тоже когда-то были обмануты, но эти жестокие истины не будут похоронены. Следы нашей борьбы не должны быть искажены и погребены.

Пишу это так много, некоторые люди наверняка захотят найти меня и уничтожить. Компания, вероятно, тоже захочет заставить меня замолчать или привлечь к ответственности. Если это произойдет, моя жизнь и безопасность, а также жизнь и безопасность моей семьи, могут оказаться под угрозой. Для самозащиты я буду ежедневно сообщать о своей безопасности.

Если я исчезну, считайте, что я пожертвовал собой ради истины и идеалов, ради лучшего развития вычислительных мощностей и ИИ в Huawei и даже в Китае. Я желаю быть похороненным там, где я когда-то боролся.

Прощай, Noah.

6 июля 2025 года, раннее утро, написано в Шэньчжэне

---

Здравствуйте, уважаемые,

Спасибо за вашу заботу и добрые пожелания. Я пока в безопасности, но компания, вероятно, проводит проверку и собирает определенные списки, дальнейшая ситуация неизвестна.

Я добавлю несколько деталей, чтобы некоторые люди не продолжали искажать факты.

Что касается 135B V2, лаборатория малых моделей, быстро завершив "упаковку" и получив все выгоды от нее (например, благодарности за выполнение задач и своевременные поощрения), не желая дальше поддерживать нижестоящие приложения и итерации модели, сбросила эту горячую картофелину на четвертый фронт. Действительно, мастерский ход, который напрямую втянул братьев из четвертого фронта. Коллега предоставил старую модель, а в итоге получил тогдашнюю модифицированную передовую Qwen. Люди, работающие с большими моделями, так же хорошо знают свои модели, как своих детей, не считайте всех дураками. Это как если бы ваш сын ушел из дома и вернулся чужим ребенком.

Подписание отчета Pangu не соответствует академическим нормам. Например, у 135B V3 многие люди, внесшие технический вклад, не получили должного вознаграждения за свой труд из-за ограничения по количеству авторов, и внутри команды были значительные возражения. Эта модель тогда была кристаллизацией коллективного разума и пота, даже духовной опорой команды в то время, поддерживающей многих братьев, чтобы они оставались в Noah. Так называемые ограничения по количеству мест и включение в авторы людей без какого-либо технического вклада (например, некоторых из лаборатории малых моделей) очень огорчили братьев.

---

Пока в безопасности. Кроме того, поддержите моих товарищей, которые осмелились сказать правду: https://github.com/HW-whistleblower/True-Story-of-Pangu/issues/317
